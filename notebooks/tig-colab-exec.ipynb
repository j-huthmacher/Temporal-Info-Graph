{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\r\n",
    "get_ipython().run_line_magic('autoreload', '2')\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.insert(0, \"../\")\r\n",
    "\r\n",
    "import pandas as pd \r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torchsummary import summary\r\n",
    "\r\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Block: Temporal Convolution\r\n",
    "\r\n",
    "Below you find some sample code to test the temporal convolution. For verification you can use the example tensor some predefined weights.\r\n",
    "\r\n",
    "In general, the `Conv2D` function from PyTorch requires some tensor with the dimensions `(N, C_in, H_in, W_in)`. In our case those dimensions corresponds to `(batch, features, nodes, time_steps)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\r\n",
    "# Create example tensor                        #\r\n",
    "# Either use a predefined tensor (uncomment)   #\r\n",
    "# or use a random generated tensor (commented) #\r\n",
    "################################################\r\n",
    "\r\n",
    "# batch = 1\r\n",
    "# features = 4\r\n",
    "# time_steps = 6\r\n",
    "# nodes = 3\r\n",
    "# X = torch.randint(0, 10, (batch, features, nodes, time_steps)).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "# Predefined example tensor for verification\r\n",
    "X = torch.tensor([[\r\n",
    "       [[1, 2, 1, 1],  # f1, n1 , t1 and t2 and t3 and t4\r\n",
    "        [3, 4, 1, 1],  # f1, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 1, 1, 1]], # f1, n3 , t1 and t2 and t3 and t4\r\n",
    "       [[2, 2, 1, 1],  # f2, n1 , t1 and t2 and t3 and t4\r\n",
    "        [2, 2, 1, 1],  # f2, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 4, 1, 1]]  # f2, n3 , t1 and t2 and t3 and t4\r\n",
    "     ]]).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "X.shape\r\n",
    "# x, y, z;Old: features, nodes, time; required: fearures, time, nodes\r\n",
    "#X.permute(0,3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\r\n",
    "# Create Temporal Convolution #\r\n",
    "###############################\r\n",
    "import sys\r\n",
    "sys.path.insert(0, \"../\")\r\n",
    "\r\n",
    "from model.temporal_info_graph import TemporalConvolution\r\n",
    "\r\n",
    "# Custom kernel! Dimension (c_out, c_in, kernel[0], kernel[1])\r\n",
    "weights = torch.ones_like(torch.randint(0, 10, (5, 2, 1, 2)).type('torch.FloatTensor'))\r\n",
    "\r\n",
    "# c_in = features, c_out can be chosen, kernel = (1, x), where x is free number less than the number of time steps.\r\n",
    "# Weights and activation are optional.\r\n",
    "tempConv = TemporalConvolution(c_in=2, c_out=2, kernel=(1, 3))#, weights=weights, activation=None).cpu()\r\n",
    "print(X.shape, tempConv(X).shape)\r\n",
    "H = tempConv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Block: Spectral Convolution\r\n",
    "\r\n",
    "Reference implementations: https://github.com/FelixOpolka/STGCN-PyTorch/blob/master/stgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\r\n",
    "get_ipython().run_line_magic('autoreload', '2')\r\n",
    "\r\n",
    "\r\n",
    "import torch\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "# Predefined example tensor for verification\r\n",
    "X = torch.tensor([[\r\n",
    "       [[1, 2, 1, 1],  # f1, n1 , t1 and t2 and t3 and t4\r\n",
    "        [3, 4, 1, 1],  # f1, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 1, 1, 1]], # f1, n3 , t1 and t2 and t3 and t4\r\n",
    "       [[2, 2, 1, 1],  # f2, n1 , t1 and t2 and t3 and t4\r\n",
    "        [2, 2, 1, 1],  # f2, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 4, 1, 1]]  # f2, n3 , t1 and t2 and t3 and t4\r\n",
    "     ]]).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "A = torch.tensor([\r\n",
    "    [0, 1, 0],\r\n",
    "    [1, 0, 1], \r\n",
    "    [0, 1, 0]\r\n",
    "    ]).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "D = torch.diag(torch.sum(A, dim=0))\r\n",
    "L = D - A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.einsum(equation, *operands)`: This function provides a way of computing multilinear expressions (i.e. sums of products) using the Einstein summation convention.\r\n",
    "\r\n",
    "**Equation**\r\n",
    "* The left hand side lists the operands dimensions, separated by commas. There should be one index letter per tensor dimension. \r\n",
    "* The right hand side follows after -> and gives the indices for the output\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\r\n",
    "# Check/Validation: This einsum corresponds to Adjacency multiplication in time #\r\n",
    "#################################################################################\r\n",
    "\r\n",
    "# lfs = torch.einsum(\"ij,jklm->kilm\", [A, X.permute(3, 0, 2, 1)])\r\n",
    "lfs = torch.einsum(\"ij,jklm->kilm\", [A, X.permute(2, 0, 3, 1)])\r\n",
    "\r\n",
    "print(lfs)#.permute(0, 2, 1, 3))\r\n",
    "# Equal to A@X.permute(0,3,2,1)[0][i], i.e. multiplying the adjacency with the feature matrix at each time step.\r\n",
    "# print(A@X.permute(0,3,2,1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\r\n",
    "# Create Spectral Convolution #\r\n",
    "###############################\r\n",
    "import sys\r\n",
    "sys.path.insert(0, \"../\")\r\n",
    "\r\n",
    "from model.temporal_info_graph import SpectralConvolution\r\n",
    "\r\n",
    "# To double check\r\n",
    "weights = torch.eye(2).type('torch.FloatTensor')\r\n",
    "\r\n",
    "# Weights and activation are optional.\r\n",
    "specConv = SpectralConvolution(c_in=2, c_out=1, weights=weights, activation = None).cpu()\r\n",
    "print(X.shape, specConv(X, A).shape, X.permute(0, 2, 1, 3).shape)\r\n",
    "specConv(X, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TemporalInfoGraph: Stacked temporal and spectral convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\r\n",
    "get_ipython().run_line_magic('autoreload', '2')\r\n",
    "\r\n",
    "import torch\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "# Predefined example tensor for verification\r\n",
    "X = torch.tensor([[\r\n",
    "       [[1, 2, 1, 1],  # f1, n1 , t1 and t2 and t3 and t4\r\n",
    "        [3, 4, 1, 1],  # f1, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 1, 1, 1]], # f1, n3 , t1 and t2 and t3 and t4\r\n",
    "       [[2, 2, 1, 1],  # f2, n1 , t1 and t2 and t3 and t4\r\n",
    "        [2, 2, 1, 1],  # f2, n2 , t1 and t2 and t3 and t4\r\n",
    "        [2, 4, 1, 1]]  # f2, n3 , t1 and t2 and t3 and t4\r\n",
    "     ]]).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "A = torch.tensor([\r\n",
    "    [0, 1, 0],\r\n",
    "    [1, 0, 1], \r\n",
    "    [0, 1, 0]\r\n",
    "    ]).type('torch.FloatTensor').cpu()\r\n",
    "\r\n",
    "D = torch.diag(torch.sum(A, dim=0))\r\n",
    "L = D - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "sys.path.insert(0, \"../\")\r\n",
    "\r\n",
    "from model.temporal_info_graph import TemporalInfoGraph\r\n",
    "\r\n",
    "# dim_in corresponds to (H, W), here (nodes, time steps)\r\n",
    "tig = TemporalInfoGraph(c_in=2, c_out=6, spec_out=9, out=7, dim_in=(3,4), tempKernel=3)\r\n",
    "gbl, lcl  = tig(X, A)\r\n",
    "print(X.shape)\r\n",
    "print(gbl.shape)\r\n",
    "# print(gbl)\r\n",
    "print(lcl.shape)\r\n",
    "# print(lcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbl.mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\r\n",
    "# Data Investigation #\r\n",
    "######################\r\n",
    "import sys\r\n",
    "sys.path.insert(0, \"../\")\r\n",
    "\r\n",
    "from data.preprocessing import create_skeleton\r\n",
    "\r\n",
    "df_val = create_skeleton(folder=\"../../../Datasets/Kinetics-skeleton/kinetics-skeleton/kinetics_val/\", cat=\"val\", lim=10, to_mongoDB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.animation import animate_skeleton\r\n",
    "\r\n",
    "# It can be that we don't have a skeleton in each frame.\r\n",
    "animate_skeleton(df_val.iloc[2], lim_frames=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## \r\n",
    "# Example: Read from MongoDB #\r\n",
    "##############################\r\n",
    "import pymongo\r\n",
    "\r\n",
    "db_url = \"\"\r\n",
    "with open(\"../.mongoURL\") as f:\r\n",
    "        db_url = f.readlines()       \r\n",
    "\r\n",
    "client = pymongo.MongoClient(db_url)\r\n",
    "\r\n",
    "collection = client.temporal_info_graph[\"kinect-skeleton\"]\r\n",
    "\r\n",
    "cursor = collection.find({})\r\n",
    "for document in cursor:\r\n",
    "        doc = pd.DataFrame([document])\r\n",
    "        break\r\n",
    "\r\n",
    "# Get feature matrix for sample 1 and frame 1\r\n",
    "X = np.asarray(doc.iloc[0][\"frames\"][0][\"feature_matrices\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\r\n",
    "# Visualize Feature Matrix (Static) #\r\n",
    "#####################################\r\n",
    "import numpy as np \r\n",
    "import networkx as nx \r\n",
    "\r\n",
    "from data import KINECT_ADJACENCY\r\n",
    "\r\n",
    "G = nx.Graph(KINECT_ADJACENCY)\r\n",
    "nx.draw(G, [(x,y) for x,y in X], node_size=50,with_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tig': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e40159a12ac9a9ece4e67df73bdf345461e79f1702abc56474bd8ff4d26a4103"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
