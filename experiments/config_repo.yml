standard:
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  data_split:
    lim: 500
  loader:
    batch_size: 32
  emb_tracking: False
  encoder: 
    c_in: 2
    c_out: 64
    spec_out: 128
    out: 2
    dim_in: [36, 300]
    tempKernel: 32
  encoder_training:
    verbose: True
    n_epochs: 5
  classifier: 
    in_dim: 2
    hidden_layers: [128, 512, 1024, 256]
  classifier_training:
    verbose: True
    n_epochs: 5

standard_stratified:
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  stratify:
    num: 5
  loader:
    batch_size: 32
  emb_tracking: False
  encoder: 
    c_in: 2
    c_out: 64
    spec_out: 128
    out: 16
    dim_in: [36, 300]
    tempKernel: 32
  encoder_training:
    verbose: True
    n_epochs: 8000
  classifier: 
    in_dim: 16
    hidden_layers: [128, 512, 1024, 256]
  classifier_training:
    verbose: True
    n_epochs: 500

standard_stratified2:
  name: AvgPooling
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  stratify:
    num: 2
    lim: 5000
  loader:
    batch_size: 4
  emb_tracking: True
  encoder: 
    architecture: [ 
      [2,    32,  64,  64, 16],
    ]
  encoder_training:
    verbose: True
    n_epochs: 5
    optimizer_name: SGD
    optimizer:
      lr: 0.2
      momentum: 0.9
    gradient_clipping: 0.2
  classifier: 
    in_dim: 512
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 5
    optimizer_name: SGD
    optimizer:
      lr: 0.1
      momentum: 0.9
    gradient_clipping: 0.2
  tracking:
    track_decision: True
  visuals: ["classification", "memory", "loss", "metric"]

complex_encoder:
  data:
    name: kinetic_skeleton_5000
    path: ./content/
    verbose: True
  loader:
    batch_size: 256
  data_split:
    lim: 20000
  emb_tracking: True
  print_summary: True
  encoder: 
    # [(c_in, c_out, spec_out, out, kernel)]
    architecture: [
      [2, 32, 64, 64, 16],
      [64, 64, 64, 64, 16],
      [64, 64, 64, 64, 16],
      [64, 64, 128, 128, 16],
      [128, 128, 256, 256, 16],
      [256, 256, 256, 256, 16],
      [256, 256, 256, 256, 16]
   ]
  encoder_training:
    verbose: True
    n_epochs: 50
    optimizer_name: SGD
    optimizer:
      lr: 0.01
      momentum: 0.9
    gradient_clipping: 0.2
  classifier: 
    in_dim: 256
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 50
    optimizer_name: SGD
    optimizer:
      lr: 0.001
      momentum: 0.9
    gradient_clipping: 0.2
  
small_complex_encoder:
  name: jsd
  data:
    name: kinetic_skeleton_5000
    path: ./content/
    verbose: True
  loader:
    batch_size: 32
    shuffle: True
  stratify:
    num: 100
    lim: 100
  emb_tracking: 10
  loss: bce
  encoder:
    architecture: [
      [2, 32, 64, 16],
      [64, 64, 64, 16],
      [64, 64, 128, 16]
   ]
    residual: True
    # edge_weights: True
  encoder_training:
    verbose: True
    n_epochs: 50
    optimizer_name: Adam
    optimizer:
      lr: 0.01
    gradient_clipping: 0.5
  classifier: 
    in_dim: 128
    hidden_layers: [128, 256, 256]
  classifier_training:
    verbose: True
    n_epochs: 10
    optimizer_name: Adam
    optimizer:
      lr: 0.01
    gradient_clipping: 0.5

evaluate_experiment:
  exp:
    path: ./output/20012021_1303_debug_small_complex_encoder/
  mode: sklearn
  classifier: 
    in_dim: 256
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 50
    optimizer_name: SGD
    optimizer:
      lr: 0.001
      momentum: 0.9
    gradient_clipping: 0.2
