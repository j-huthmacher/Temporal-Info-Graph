standard:
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  data_split:
    lim: 500
  loader:
    batch_size: 32
  emb_tracking: False
  encoder: 
    c_in: 2
    c_out: 64
    spec_out: 128
    out: 2
    dim_in: [36, 300]
    tempKernel: 32
  encoder_training:
    verbose: True
    n_epochs: 5
  classifier: 
    in_dim: 2
    hidden_layers: [128, 512, 1024, 256]
  classifier_training:
    verbose: True
    n_epochs: 5

standard_stratified:
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  stratify:
    num: 5
  loader:
    batch_size: 32
  emb_tracking: False
  encoder: 
    c_in: 2
    c_out: 64
    spec_out: 128
    out: 16
    dim_in: [36, 300]
    tempKernel: 32
  encoder_training:
    verbose: True
    n_epochs: 8000
  classifier: 
    in_dim: 16
    hidden_layers: [128, 512, 1024, 256]
  classifier_training:
    verbose: True
    n_epochs: 500

standard_stratified2:
  name: AvgPooling
  data:
    name: kinetic_skeleton_5000
    path: ./content/
  stratify:
    num: 2
    lim: 5000
  loader:
    batch_size: 4
  emb_tracking: True
  encoder: 
    architecture: [ 
      [2,    32,  64,  64, 16],
    ]
  encoder_training:
    verbose: True
    n_epochs: 5
    optimizer_name: SGD
    optimizer:
      lr: 0.2
      momentum: 0.9
    gradient_clipping: 0.2
  classifier: 
    in_dim: 512
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 5
    optimizer_name: SGD
    optimizer:
      lr: 0.1
      momentum: 0.9
    gradient_clipping: 0.2
  tracking:
    track_decision: True
  visuals: ["classification", "memory", "loss", "metric"]

complex_encoder:
  name: 5classes_2spec_dif_scales
  data:
    name: kinetic_skeleton_5000
    path: ./content/
    verbose: True
  loader: 
    batch_size: 256
    shuffle: True
  stratify: 
    num: 10
    lim: 5000
  emb_tracking: 10
  loss: bce
  print_summary: True
  encoder: 
    # [(c_in, c_out, spec_out, out, kernel)]
    architecture: [
      [2, 32, 64, 64, 22],
      [64, 64, 64, 64, 22],
      [64, 64, 64, 64, 22],
      [64, 64, 128, 128, 22],
      [128, 128, 256, 256, 22],
      [256, 256, 256, 256, 22],
      [256, 256, 256, 256, 22]
   ]
    residual: True
    discriminator_layer: False
    dropout': 0
  encoder_training:
    verbose: True
    n_epochs: 2000
    optimizer_name: Adam
    optimizer:
      lr: 0.01
    gradient_clipping: 0.2
  classifier: 
    in_dim: 256
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 50
    optimizer_name: Adam
    optimizer:
      lr: 0.01
    gradient_clipping: 0.2
  
small_complex_encoder:
  name: fcn_1spec_1000epochs_MLP_LR_0_001_diff_scales
  # tracking:
  #   local_path: ./output/17022021_1838_debug_small_complex_encoder_fcn_1spec_diff_scale/
  data:
    name: stgcn_2080
    path: ./content/
    verbose: True
  loader:
    batch_size: 16
    shuffle: True
  stratify:
    num: 2
    lim: 100
  emb_tracking: 10
  loss: bce
  encoder:
    architecture: [
      [2, 64, 64, 64, 37],
      [64, 64, 64, 64, 37],
      [64, 64, 64, 64, 37],
      [64, 64, 64, 64, 37]]
    residual: True
    # edge_weights: True
    discriminator_layer: False
    dropout: 0
    diff_scales: True
  encoder_training:
    verbose: True
    n_epochs: 1000
    optimizer_name: Adam
    optimizer:
      lr: 0.01
      # weight_decay: 0.001
    # gradient_clipping: 0.5
  classifier: 
    in_dim: 256
    hidden_layers: [128, 256, 256] #[256, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 100
    optimizer_name: Adam
    optimizer:
      lr: 0.001
    gradient_clipping: 0.5

evaluate_experiment:
  exp:
    path: ./output/20012021_1303_debug_small_complex_encoder/
  mode: sklearn
  classifier: 
    in_dim: 256
    hidden_layers: [128, 512, 256]
  classifier_training:
    verbose: True
    n_epochs: 50
    optimizer_name: SGD
    optimizer:
      lr: 0.001
      momentum: 0.9
    gradient_clipping: 0.2
